{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hopan/.local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('numerai_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.000000</td>\n",
       "      <td>535713.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.472921</td>\n",
       "      <td>0.482357</td>\n",
       "      <td>0.538887</td>\n",
       "      <td>0.489979</td>\n",
       "      <td>0.536681</td>\n",
       "      <td>0.531812</td>\n",
       "      <td>0.465629</td>\n",
       "      <td>0.486717</td>\n",
       "      <td>0.532687</td>\n",
       "      <td>0.495880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469072</td>\n",
       "      <td>0.506042</td>\n",
       "      <td>0.509686</td>\n",
       "      <td>0.491432</td>\n",
       "      <td>0.505670</td>\n",
       "      <td>0.525091</td>\n",
       "      <td>0.539248</td>\n",
       "      <td>0.482097</td>\n",
       "      <td>0.496385</td>\n",
       "      <td>0.49996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113607</td>\n",
       "      <td>0.117309</td>\n",
       "      <td>0.100929</td>\n",
       "      <td>0.129855</td>\n",
       "      <td>0.095137</td>\n",
       "      <td>0.111722</td>\n",
       "      <td>0.112765</td>\n",
       "      <td>0.114449</td>\n",
       "      <td>0.113772</td>\n",
       "      <td>0.115777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122965</td>\n",
       "      <td>0.116461</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>0.125189</td>\n",
       "      <td>0.105082</td>\n",
       "      <td>0.134487</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.128133</td>\n",
       "      <td>0.127438</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018030</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.392630</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.470580</td>\n",
       "      <td>0.398310</td>\n",
       "      <td>0.477130</td>\n",
       "      <td>0.455020</td>\n",
       "      <td>0.388070</td>\n",
       "      <td>0.406730</td>\n",
       "      <td>0.456450</td>\n",
       "      <td>0.416750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382760</td>\n",
       "      <td>0.429080</td>\n",
       "      <td>0.427670</td>\n",
       "      <td>0.405710</td>\n",
       "      <td>0.434630</td>\n",
       "      <td>0.432880</td>\n",
       "      <td>0.474910</td>\n",
       "      <td>0.390870</td>\n",
       "      <td>0.407310</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.467900</td>\n",
       "      <td>0.481960</td>\n",
       "      <td>0.537910</td>\n",
       "      <td>0.481050</td>\n",
       "      <td>0.542930</td>\n",
       "      <td>0.531650</td>\n",
       "      <td>0.467170</td>\n",
       "      <td>0.483680</td>\n",
       "      <td>0.535040</td>\n",
       "      <td>0.495290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466460</td>\n",
       "      <td>0.507890</td>\n",
       "      <td>0.506990</td>\n",
       "      <td>0.491250</td>\n",
       "      <td>0.504690</td>\n",
       "      <td>0.529390</td>\n",
       "      <td>0.540200</td>\n",
       "      <td>0.477660</td>\n",
       "      <td>0.488770</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.548840</td>\n",
       "      <td>0.561510</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.574150</td>\n",
       "      <td>0.602040</td>\n",
       "      <td>0.608950</td>\n",
       "      <td>0.543420</td>\n",
       "      <td>0.563750</td>\n",
       "      <td>0.611210</td>\n",
       "      <td>0.574360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552350</td>\n",
       "      <td>0.584660</td>\n",
       "      <td>0.588970</td>\n",
       "      <td>0.577010</td>\n",
       "      <td>0.576010</td>\n",
       "      <td>0.620770</td>\n",
       "      <td>0.604720</td>\n",
       "      <td>0.569660</td>\n",
       "      <td>0.579850</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.982560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969610</td>\n",
       "      <td>0.982570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature1       feature2       feature3       feature4  \\\n",
       "count  535713.000000  535713.000000  535713.000000  535713.000000   \n",
       "mean        0.472921       0.482357       0.538887       0.489979   \n",
       "std         0.113607       0.117309       0.100929       0.129855   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.392630       0.401900       0.470580       0.398310   \n",
       "50%         0.467900       0.481960       0.537910       0.481050   \n",
       "75%         0.548840       0.561510       0.606200       0.574150   \n",
       "max         0.982560       1.000000       1.000000       1.000000   \n",
       "\n",
       "            feature5       feature6       feature7       feature8  \\\n",
       "count  535713.000000  535713.000000  535713.000000  535713.000000   \n",
       "mean        0.536681       0.531812       0.465629       0.486717   \n",
       "std         0.095137       0.111722       0.112765       0.114449   \n",
       "min         0.038720       0.000000       0.006410       0.000000   \n",
       "25%         0.477130       0.455020       0.388070       0.406730   \n",
       "50%         0.542930       0.531650       0.467170       0.483680   \n",
       "75%         0.602040       0.608950       0.543420       0.563750   \n",
       "max         0.969610       0.982570       1.000000       0.982170   \n",
       "\n",
       "            feature9      feature10      ...           feature42  \\\n",
       "count  535713.000000  535713.000000      ...       535713.000000   \n",
       "mean        0.532687       0.495880      ...            0.469072   \n",
       "std         0.113772       0.115777      ...            0.122965   \n",
       "min         0.000000       0.000000      ...            0.000000   \n",
       "25%         0.456450       0.416750      ...            0.382760   \n",
       "50%         0.535040       0.495290      ...            0.466460   \n",
       "75%         0.611210       0.574360      ...            0.552350   \n",
       "max         1.000000       1.000000      ...            1.000000   \n",
       "\n",
       "           feature43      feature44      feature45      feature46  \\\n",
       "count  535713.000000  535713.000000  535713.000000  535713.000000   \n",
       "mean        0.506042       0.509686       0.491432       0.505670   \n",
       "std         0.116461       0.118462       0.125189       0.105082   \n",
       "min         0.000000       0.064210       0.000000       0.000000   \n",
       "25%         0.429080       0.427670       0.405710       0.434630   \n",
       "50%         0.507890       0.506990       0.491250       0.504690   \n",
       "75%         0.584660       0.588970       0.577010       0.576010   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "           feature47      feature48      feature49      feature50  \\\n",
       "count  535713.000000  535713.000000  535713.000000  535713.000000   \n",
       "mean        0.525091       0.539248       0.482097       0.496385   \n",
       "std         0.134487       0.096700       0.128133       0.127438   \n",
       "min         0.004120       0.027490       0.000000       0.018030   \n",
       "25%         0.432880       0.474910       0.390870       0.407310   \n",
       "50%         0.529390       0.540200       0.477660       0.488770   \n",
       "75%         0.620770       0.604720       0.569660       0.579850   \n",
       "max         1.000000       1.000000       0.994200       1.000000   \n",
       "\n",
       "             target  \n",
       "count  535713.00000  \n",
       "mean        0.49996  \n",
       "std         0.50000  \n",
       "min         0.00000  \n",
       "25%         0.00000  \n",
       "50%         0.00000  \n",
       "75%         1.00000  \n",
       "max         1.00000  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'feature1', u'feature2', u'feature3', u'feature4', u'feature5',\n",
      "       u'feature6', u'feature7', u'feature8', u'feature9', u'feature10',\n",
      "       u'feature11', u'feature12', u'feature13', u'feature14', u'feature15',\n",
      "       u'feature16', u'feature17', u'feature18', u'feature19', u'feature20',\n",
      "       u'feature21', u'feature22', u'feature23', u'feature24', u'feature25',\n",
      "       u'feature26', u'feature27', u'feature28', u'feature29', u'feature30',\n",
      "       u'feature31', u'feature32', u'feature33', u'feature34', u'feature35',\n",
      "       u'feature36', u'feature37', u'feature38', u'feature39', u'feature40',\n",
      "       u'feature41', u'feature42', u'feature43', u'feature44', u'feature45',\n",
      "       u'feature46', u'feature47', u'feature48', u'feature49', u'feature50'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feat_cols = df.columns[3:-1]\n",
    "target_col = df.columns[-1]\n",
    "print feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def era_split(df, col, test_size=0.1, seed=0):\n",
    "    # sample a bunch of eras to use as the test set\n",
    "    uniques = df[col].unique()\n",
    "    num_unique = len(df[col].unique())\n",
    "    test_count = int(num_unique * test_size)\n",
    "    train_count = num_unique - test_count\n",
    "\n",
    "    test_eras = np.random.choice(uniques, size=test_count, replace=False)\n",
    "    test_set = df[df[col].isin(test_eras)]\n",
    "    train_set = df[~df[col].isin(test_eras)]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_target(df, feat_col, target_col):\n",
    "    return df[feat_col], df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = era_split(df, 'era', test_size=0.2)\n",
    "x_train, y_train = get_feat_target(train, feat_cols, target_col)\n",
    "x_test, y_test = get_feat_target(test, feat_cols, target_col)\n",
    "data_dict = {\n",
    "    'x_train': x_train,\n",
    "    'x_test': x_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test\n",
    "}\n",
    "\n",
    "smaller_size = 1000\n",
    "small_data_dict = {\n",
    "    'x_train': x_train[:smaller_size],\n",
    "    'x_test': x_test[smaller_size: 2*smaller_size],\n",
    "    'y_train': y_train[:smaller_size],\n",
    "    'y_test': y_test[smaller_size:2*smaller_size]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation params\n",
    "def get_cv_params(model_func):\n",
    "    lr_params = {\n",
    "        'C': [10**i for i in range(-3, 3)]\n",
    "    }\n",
    "\n",
    "    rf_dict = {\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 10, 100],\n",
    "        'max_depth': [5, 10, 15],\n",
    "    }\n",
    "\n",
    "    gbt_dict = {                                                                                      \n",
    "        'learning_rate': [0.1, 0.25, 0.5],                                                              \n",
    "        'max_depth': [5, 10, 15],                                                                            \n",
    "        'min_samples_split': [2, 5],                                                                    \n",
    "        'min_samples_leaf': [1, 10, 100],\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        LogisticRegression: lr_params,\n",
    "        RandomForestClassifier: rf_dict,\n",
    "        GradientBoostingClassifier: gbt_dict\n",
    "    }\n",
    "    \n",
    "    return params.get(model_func, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_model(model, param_dict, scoring, data_dict, folds=10, n_jobs=4):\n",
    "    x_train = data_dict['x_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    x_test = data_dict['x_test']\n",
    "    y_test = data_dict['y_test']\n",
    "\n",
    "    gridcv = GridSearchCV(model, param_dict, scoring=scoring, cv=folds, n_jobs=n_jobs)\n",
    "    gridcv.fit(x_train, y_train)\n",
    "\n",
    "    best_model = gridcv.best_estimator_\n",
    "    y_pred = best_model.predict_proba(x_test)\n",
    "    loss = log_loss(y_test, y_pred)\n",
    "    return loss, best_model, gridcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_all_cv(data_dict, folds=5, n_jobs=4):\n",
    "    # Run cross validation for each model.\n",
    "    model_funcs = [LogisticRegression, RandomForestClassifier, GradientBoostingClassifier]\n",
    "    for m in model_funcs:\n",
    "        print '=' * 80\n",
    "        print m.__name__\n",
    "        model = m()\n",
    "        cv_params = get_cv_params(m)\n",
    "        loss, best_model, gridcv = cv_model(model, cv_params, 'accuracy', data_dict, folds=folds, n_jobs=n_jobs)\n",
    "        print '{}\\nLoss: {}'.format(best_model, loss)\n",
    "        print gridcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "run_all_cv(data_dict, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
